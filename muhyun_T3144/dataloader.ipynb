{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd825284-476b-4f36-a642-d282f0345e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d6f796b-6709-483b-aa65-ec5f8b7e03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/opt/ml/input/data/train/images'\n",
    "TEST_DIR = '/opt/ml/input/data/eval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a43f005-85e4-45eb-92e3-0f22fac3cc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/input/data/train/images/006621_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/input/data/train/images/006621_male_As...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/input/data/train/images/006621_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/input/data/train/images/006621_male_As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/input/data/train/images/006621_male_As...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  label\n",
       "0  /opt/ml/input/data/train/images/006621_male_As...      0\n",
       "1  /opt/ml/input/data/train/images/006621_male_As...      6\n",
       "2  /opt/ml/input/data/train/images/006621_male_As...      0\n",
       "3  /opt/ml/input/data/train/images/006621_male_As...      0\n",
       "4  /opt/ml/input/data/train/images/006621_male_As...     12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./train_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791f8084-91d6-4e72-b4e3-c9f24e2b4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_split, val_data_split = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2, \n",
    "    shuffle=True, \n",
    "    stratify=data['label'],\n",
    "    random_state=34,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b465048d-ff1c-4870-a335-ce2a42cb2012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 2)\n",
      "(3780, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15120, 2), (3780, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data_split.shape)\n",
    "print(val_data_split.shape)\n",
    "train_data_split.shape, val_data_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894bc112-e0b1-4b43-a34f-2ceac8b28099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, image_data, transform):\n",
    "        self.img_path = image_data['image_path']\n",
    "        self.label = image_data['label']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_path.iloc[idx])\n",
    "        label = self.label.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70dc3a8b-09a8-41d4-a307-4269559cd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64df2e0f-99db-4073-847a-333bfabab26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0002\n",
    "NUM_CLASSES = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e234105-9465-4c96-9247-79ddde00d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataSet(train_data_split, transform=transform)\n",
    "val_data = CustomDataSet(val_data_split, transform=transform)\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62af423e-bfd1-4e38-8ede-5c225c9fa20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 300, 300])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58956866-c59c-4039-b8f6-3a63409f7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b856fd1-b66f-4b98-9a51-762380620cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loader_type = {\n",
    "    \"train\": train_data_loader,\n",
    "    \"test\": val_data_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddbb077b-5616-4c8e-86b0-ecfd62594f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.fc = torch.nn.Linear(in_features = 512, out_features=NUM_CLASSES, bias=True)\n",
    "\n",
    "torch.nn.init.xavier_uniform_(resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(resnet18.fc.weight.size(1))\n",
    "resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "resnet18.fc.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c78aa56-6a05-4754-b305-5e2ca914327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba81201e-70b3-4ba4-9f67-fd3bce713e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train-데이터 셋 Loss: 0.396, acc: 0.876\n",
      "epoch: 1, test-데이터 셋 Loss: 0.163, acc: 0.943\n",
      "epoch: 2, train-데이터 셋 Loss: 0.068, acc: 0.980\n",
      "epoch: 2, test-데이터 셋 Loss: 0.193, acc: 0.934\n",
      "epoch: 3, train-데이터 셋 Loss: 0.045, acc: 0.987\n",
      "epoch: 3, test-데이터 셋 Loss: 0.114, acc: 0.961\n",
      "epoch: 4, train-데이터 셋 Loss: 0.028, acc: 0.992\n",
      "epoch: 4, test-데이터 셋 Loss: 0.039, acc: 0.987\n",
      "epoch: 5, train-데이터 셋 Loss: 0.007, acc: 0.998\n",
      "epoch: 5, test-데이터 셋 Loss: 0.049, acc: 0.983\n",
      "epoch: 6, train-데이터 셋 Loss: 0.019, acc: 0.995\n",
      "epoch: 6, test-데이터 셋 Loss: 0.120, acc: 0.960\n",
      "epoch: 7, train-데이터 셋 Loss: 0.049, acc: 0.984\n",
      "epoch: 7, test-데이터 셋 Loss: 0.156, acc: 0.950\n",
      "finished by early stopping!!\n",
      "training end!!\n",
      "best acc: 0.9870370626449585, best loss: 0.03905134182324801\n"
     ]
    }
   ],
   "source": [
    "resnet18.to(device)\n",
    "best_test_acc = 0\n",
    "best_test_loss = 9999.\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for mode in [\"train\", \"test\"]:\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        if mode == 'train':\n",
    "            resnet18.train()\n",
    "        elif mode == 'test':\n",
    "            resnet18.eval()\n",
    "        \n",
    "        for idx, (images, labels) in enumerate(loader_type[mode]):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(mode == 'train'):\n",
    "                logits = resnet18(images)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                if mode == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(loader_type[mode].dataset)\n",
    "        epoch_acc = running_acc / len(loader_type[mode].dataset)\n",
    "        \n",
    "        print(f'epoch: {epoch+1}, {mode}-데이터 셋 Loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n",
    "        if mode == 'test' and best_test_acc < epoch_acc:\n",
    "              best_test_acc = epoch_acc\n",
    "        if mode == 'test' and best_test_loss > epoch_loss:\n",
    "              best_test_loss = epoch_loss\n",
    "        elif mode == 'test' and best_test_loss < epoch_loss:\n",
    "            patience += 1\n",
    "    \n",
    "    if patience == 4:\n",
    "        print('finished by early stopping!!')\n",
    "        break\n",
    "        \n",
    "print(\"training end!!\")\n",
    "print(f\"best acc: {best_test_acc}, best loss: {best_test_loss}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985d664a-9b6c-45e1-9f2f-79801e3cd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 w, b만 저장\n",
    "torch.save(resnet18.state_dict(), f'batch_size_{BATCH_SIZE}_epoch_{EPOCHS}_learning_rate_{LEARNING_RATE}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2551f2fb-d9ec-4cf3-bf43-2515a3fb3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1257cfe9-c248-4c3f-8e32-0b6e69760141",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(TEST_DIR, 'info.csv'))\n",
    "image_dir = os.path.join(TEST_DIR, 'images')\n",
    "\n",
    "image_paths = [os.path.join(image_dir, img_path) for img_path in submission['ImageID']]\n",
    "\n",
    "test_data = TestDataset(image_paths, transform=transform)\n",
    "test_data_loader = DataLoader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64b673f4-de24-4e0e-9ab9-969973b5eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully done!\n"
     ]
    }
   ],
   "source": [
    "resnet18.eval()\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for images in test_data_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = resnet18(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "submission.to_csv(f'{TEST_DIR}/submission.csv', index=False)\n",
    "\n",
    "print('successfully done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e94ca-dc0b-4dfa-b66b-aa4c5577d545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
